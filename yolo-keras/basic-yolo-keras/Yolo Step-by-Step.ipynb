{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline of Steps**\n",
    "    + Initialization\n",
    "        + Download COCO detection data from http://cocodataset.org/#download\n",
    "            + http://images.cocodataset.org/zips/train2014.zip <= train images\n",
    "            + http://images.cocodataset.org/zips/val2014.zip <= validation images\n",
    "            + http://images.cocodataset.org/annotations/annotations_trainval2014.zip <= train and validation annotations\n",
    "        + Run this script to convert annotations in COCO format to VOC format\n",
    "            + https://gist.github.com/chicham/6ed3842d0d2014987186#file-coco2pascal-py\n",
    "        + Download pre-trained weights from https://pjreddie.com/darknet/yolo/\n",
    "            + https://pjreddie.com/media/files/yolo.weights\n",
    "        + Specify the directory of train annotations (train_annot_folder) and train images (train_image_folder)\n",
    "        + Specify the directory of validation annotations (valid_annot_folder) and validation images (valid_image_folder)\n",
    "        + Specity the path of pre-trained weights by setting variable *wt_path*\n",
    "    + Construct equivalent network in Keras\n",
    "        + Network arch from https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg\n",
    "    + Load the pretrained weights\n",
    "    + Perform training \n",
    "    + Perform detection on an image with newly trained weights\n",
    "    + Perform detection on an video with newly trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:33:44.138409Z",
     "start_time": "2017-11-26T12:33:41.531465Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2\n",
    "from preprocessing import parse_annotation, BatchGenerator\n",
    "from utils import WeightReader, decode_netout, draw_boxes, normalize\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:33:52.507849Z",
     "start_time": "2017-11-26T12:33:52.487930Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "labels = ['joe','ladder','skull','key','door','belt','rope']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(labels) #len(LABELS) \n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:33:56.177021Z",
     "start_time": "2017-11-26T12:33:56.172746Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt_path = 'yolo.weights'                      \n",
    "#train_image_folder = '../../raccoon_dataset/train_image_folder/'\n",
    "#train_annot_folder = '../../raccoon_dataset/train_annot_folder/'\n",
    "#valid_image_folder = '../../raccoon_dataset/valid_image_folder/'\n",
    "#valid_annot_folder = '../../raccoon_dataset/valid_annot_folder/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:33:58.179391Z",
     "start_time": "2017-11-26T12:33:58.175696Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:01.523076Z",
     "start_time": "2017-11-26T12:34:00.007828Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 23\n",
    "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "\n",
    "# small hack to allow true_boxes to be registered when Keras build the model \n",
    "# for more information: https://github.com/fchollet/keras/issues/2790\n",
    "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
    "\n",
    "model = Model([input_image, true_boxes], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 23\n",
    "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "\n",
    "# small hack to allow true_boxes to be registered when Keras build the model \n",
    "# for more information: https://github.com/fchollet/keras/issues/2790\n",
    "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
    "\n",
    "model = Model([input_image, true_boxes], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output = Lambda(lambda args: args[0])([3, 1])\n",
    "map(lambda args: args[0], [np.array([3,2]), np.array([1,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:03.819802Z",
     "start_time": "2017-11-26T12:34:03.786125Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 208, 208, 32) 0           leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 104, 104, 64) 0           leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 13, 13, 512)  0           leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 13, 13, 256)  0           leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 13, 13, 1280) 0           lambda_3[0][0]                   \n",
      "                                                                 leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 60)   61500       leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 13, 13, 5, 12 0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 1, 1, 50,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 13, 13, 5, 12 0           reshape_2[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,609,436\n",
      "Trainable params: 50,588,764\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the weights originally provided by YOLO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:06.976188Z",
     "start_time": "2017-11-26T12:34:06.232200Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_reader = WeightReader(wt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:11.559043Z",
     "start_time": "2017-11-26T12:34:08.310987Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_reader.reset()\n",
    "nb_conv = 23\n",
    "\n",
    "for i in range(1, nb_conv+1):\n",
    "    conv_layer = model.get_layer('conv_' + str(i))\n",
    "    \n",
    "    if i < nb_conv:\n",
    "        norm_layer = model.get_layer('norm_' + str(i))\n",
    "        \n",
    "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "        beta  = weight_reader.read_bytes(size)\n",
    "        gamma = weight_reader.read_bytes(size)\n",
    "        mean  = weight_reader.read_bytes(size)\n",
    "        var   = weight_reader.read_bytes(size)\n",
    "\n",
    "        weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
    "        \n",
    "    if len(conv_layer.get_weights()) > 1:\n",
    "        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel, bias])\n",
    "    else:\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomize weights of the last layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T14:08:00.245248Z",
     "start_time": "2017-11-22T14:08:00.215495Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer   = model.layers[-4] # the last convolutional layer\n",
    "weights = layer.get_weights()\n",
    "\n",
    "new_kernel = np.random.normal(size=weights[0].shape)/(GRID_H*GRID_W)\n",
    "new_bias   = np.random.normal(size=weights[1].shape)/(GRID_H*GRID_W)\n",
    "\n",
    "layer.set_weights([new_kernel, new_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-01T20:44:50.211553",
     "start_time": "2017-02-01T20:44:50.206006"
    }
   },
   "source": [
    "$$\\begin{multline}\n",
    "\\lambda_\\textbf{coord}\n",
    "\\sum_{i = 0}^{S^2}\n",
    "    \\sum_{j = 0}^{B}\n",
    "     L_{ij}^{\\text{obj}}\n",
    "            \\left[\n",
    "            \\left(\n",
    "                x_i - \\hat{x}_i\n",
    "            \\right)^2 +\n",
    "            \\left(\n",
    "                y_i - \\hat{y}_i\n",
    "            \\right)^2\n",
    "            \\right]\n",
    "\\\\\n",
    "+ \\lambda_\\textbf{coord} \n",
    "\\sum_{i = 0}^{S^2}\n",
    "    \\sum_{j = 0}^{B}\n",
    "         L_{ij}^{\\text{obj}}\n",
    "         \\left[\n",
    "        \\left(\n",
    "            \\sqrt{w_i} - \\sqrt{\\hat{w}_i}\n",
    "        \\right)^2 +\n",
    "        \\left(\n",
    "            \\sqrt{h_i} - \\sqrt{\\hat{h}_i}\n",
    "        \\right)^2\n",
    "        \\right]\n",
    "\\\\\n",
    "+ \\sum_{i = 0}^{S^2}\n",
    "    \\sum_{j = 0}^{B}\n",
    "        L_{ij}^{\\text{obj}}\n",
    "        \\left(\n",
    "            C_i - \\hat{C}_i\n",
    "        \\right)^2\n",
    "\\\\\n",
    "+ \\lambda_\\textrm{noobj}\n",
    "\\sum_{i = 0}^{S^2}\n",
    "    \\sum_{j = 0}^{B}\n",
    "    L_{ij}^{\\text{noobj}}\n",
    "        \\left(\n",
    "            C_i - \\hat{C}_i\n",
    "        \\right)^2\n",
    "\\\\\n",
    "+ \\sum_{i = 0}^{S^2}\n",
    "L_i^{\\text{obj}}\n",
    "    \\sum_{c \\in \\textrm{classes}}\n",
    "        \\left(\n",
    "            p_i(c) - \\hat{p}_i(c)\n",
    "        \\right)^2\n",
    "\\end{multline}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:28.064549Z",
     "start_time": "2017-11-26T12:34:27.800510Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    \n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
    "    \n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "    \n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "    \n",
    "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "\n",
    "    \"\"\"\n",
    "    Debugging code\n",
    "    \"\"\"    \n",
    "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
    "    total_recall = tf.assign_add(total_recall, current_recall) \n",
    "\n",
    "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse the annotations to construct train generator and validation generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:38:44.283547Z",
     "start_time": "2017-11-26T12:38:44.277155Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : labels,\n",
    "    'CLASS'           : len(labels),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text_dir = '/Users/sw/programming/10703/project/test_images/train_annot_folder'\n",
    "train_img_dir = '/Users/sw/programming/10703/project/test_images/train_image_folder'\n",
    "valid_text_dir = '/Users/sw/programming/10703/project/test_images/valid_annot_folder'\n",
    "valid_img_dir = '/Users/sw/programming/10703/project/test_images/valid_image_folder'\n",
    "labels = ['joe','ladder','skull','key','door','belt','rope']\n",
    "\n",
    "train_imgs, seen_train_labels = parse_annotation(train_text_dir, train_img_dir, labels=labels)\n",
    "### write parsed annotations to pickle for fast retrieval next time\n",
    "#with open('train_imgs', 'wb') as fp:\n",
    "#    pickle.dump(train_imgs, fp)\n",
    "\n",
    "### read saved pickle of parsed annotations\n",
    "#with open ('train_imgs', 'rb') as fp:\n",
    "#    train_imgs = pickle.load(fp)\n",
    "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
    "\n",
    "valid_imgs, seen_valid_labels = parse_annotation(valid_text_dir, valid_img_dir, labels=labels)\n",
    "### write parsed annotations to pickle for fast retrieval next time\n",
    "#with open('valid_imgs', 'wb') as fp:\n",
    "#    pickle.dump(valid_imgs, fp)\n",
    "\n",
    "### read saved pickle of parsed annotations\n",
    "#with open ('valid_imgs', 'rb') as fp:\n",
    "#    valid_imgs = pickle.load(fp)\n",
    "valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'height': 210, 'width': 160, 'object': [{'xmin': 75, 'ymin': 71, 'name': 'joe', 'xmax': 86, 'ymax': 92}, {'xmin': 11, 'ymin': 98, 'name': 'key', 'xmax': 23, 'ymax': 114}, {'xmin': 83, 'ymin': 165, 'name': 'skull', 'xmax': 95, 'ymax': 180}, {'xmin': 17, 'ymin': 137, 'name': 'ladder', 'xmax': 35, 'ymax': 182}, {'xmin': 128, 'ymin': 137, 'name': 'ladder', 'xmax': 143, 'ymax': 182}, {'xmin': 70, 'ymin': 92, 'name': 'ladder', 'xmax': 90, 'ymax': 134}, {'xmin': 14, 'ymin': 51, 'name': 'door', 'xmax': 26, 'ymax': 92}, {'xmin': 133, 'ymin': 53, 'name': 'door', 'xmax': 144, 'ymax': 92}, {'xmin': 56, 'ymin': 133, 'name': 'belt', 'xmax': 77, 'ymax': 145}, {'xmin': 106, 'ymin': 95, 'name': 'rope', 'xmax': 117, 'ymax': 138}, {'xmin': 82, 'ymin': 134, 'name': 'belt', 'xmax': 101, 'ymax': 146}], 'filename': '/Users/sw/programming/10703/project/test_images/train_image_folder/5.png'}, {'height': 210, 'width': 160, 'object': [{'xmin': 75, 'ymin': 71, 'name': 'joe', 'xmax': 86, 'ymax': 92}, {'xmin': 11, 'ymin': 98, 'name': 'key', 'xmax': 23, 'ymax': 114}, {'xmin': 81, 'ymin': 165, 'name': 'skull', 'xmax': 94, 'ymax': 179}, {'xmin': 17, 'ymin': 137, 'name': 'ladder', 'xmax': 35, 'ymax': 182}, {'xmin': 128, 'ymin': 137, 'name': 'ladder', 'xmax': 143, 'ymax': 182}, {'xmin': 70, 'ymin': 92, 'name': 'ladder', 'xmax': 90, 'ymax': 134}, {'xmin': 14, 'ymin': 51, 'name': 'door', 'xmax': 26, 'ymax': 92}, {'xmin': 133, 'ymin': 53, 'name': 'door', 'xmax': 144, 'ymax': 92}, {'xmin': 56, 'ymin': 133, 'name': 'belt', 'xmax': 77, 'ymax': 145}, {'xmin': 106, 'ymin': 95, 'name': 'rope', 'xmax': 117, 'ymax': 138}, {'xmin': 82, 'ymin': 134, 'name': 'belt', 'xmax': 101, 'ymax': 146}], 'filename': '/Users/sw/programming/10703/project/test_images/train_image_folder/7.png'}, {'height': 210, 'width': 160, 'object': [{'xmin': 75, 'ymin': 72, 'name': 'joe', 'xmax': 86, 'ymax': 93}, {'xmin': 11, 'ymin': 98, 'name': 'key', 'xmax': 21, 'ymax': 116}, {'xmin': 88, 'ymin': 165, 'name': 'skull', 'xmax': 100, 'ymax': 180}, {'xmin': 17, 'ymin': 137, 'name': 'ladder', 'xmax': 35, 'ymax': 182}, {'xmin': 128, 'ymin': 137, 'name': 'ladder', 'xmax': 143, 'ymax': 182}, {'xmin': 70, 'ymin': 93, 'name': 'ladder', 'xmax': 90, 'ymax': 135}, {'xmin': 14, 'ymin': 52, 'name': 'door', 'xmax': 27, 'ymax': 93}, {'xmin': 133, 'ymin': 53, 'name': 'door', 'xmax': 144, 'ymax': 93}, {'xmin': 56, 'ymin': 133, 'name': 'belt', 'xmax': 77, 'ymax': 145}, {'xmin': 106, 'ymin': 95, 'name': 'rope', 'xmax': 117, 'ymax': 138}, {'xmin': 83, 'ymin': 134, 'name': 'belt', 'xmax': 101, 'ymax': 146}], 'filename': '/Users/sw/programming/10703/project/test_images/train_image_folder/0.png'}, {'height': 210, 'width': 160, 'object': [{'xmin': 75, 'ymin': 71, 'name': 'joe', 'xmax': 86, 'ymax': 92}, {'xmin': 11, 'ymin': 98, 'name': 'key', 'xmax': 23, 'ymax': 114}, {'xmin': 84, 'ymin': 165, 'name': 'skull', 'xmax': 96, 'ymax': 180}, {'xmin': 17, 'ymin': 137, 'name': 'ladder', 'xmax': 35, 'ymax': 182}, {'xmin': 128, 'ymin': 137, 'name': 'ladder', 'xmax': 143, 'ymax': 182}, {'xmin': 70, 'ymin': 92, 'name': 'ladder', 'xmax': 90, 'ymax': 134}, {'xmin': 14, 'ymin': 51, 'name': 'door', 'xmax': 26, 'ymax': 92}, {'xmin': 133, 'ymin': 53, 'name': 'door', 'xmax': 144, 'ymax': 92}, {'xmin': 56, 'ymin': 133, 'name': 'belt', 'xmax': 77, 'ymax': 145}, {'xmin': 106, 'ymin': 95, 'name': 'rope', 'xmax': 117, 'ymax': 138}, {'xmin': 82, 'ymin': 134, 'name': 'belt', 'xmax': 101, 'ymax': 146}], 'filename': '/Users/sw/programming/10703/project/test_images/train_image_folder/6.png'}, {'height': 210, 'width': 160, 'object': [{'xmin': 75, 'ymin': 71, 'name': 'joe', 'xmax': 86, 'ymax': 92}, {'xmin': 11, 'ymin': 98, 'name': 'key', 'xmax': 23, 'ymax': 114}, {'xmin': 86, 'ymin': 165, 'name': 'skull', 'xmax': 98, 'ymax': 180}, {'xmin': 17, 'ymin': 137, 'name': 'ladder', 'xmax': 35, 'ymax': 182}, {'xmin': 128, 'ymin': 137, 'name': 'ladder', 'xmax': 143, 'ymax': 182}, {'xmin': 70, 'ymin': 92, 'name': 'ladder', 'xmax': 90, 'ymax': 134}, {'xmin': 14, 'ymin': 51, 'name': 'door', 'xmax': 26, 'ymax': 92}, {'xmin': 133, 'ymin': 53, 'name': 'door', 'xmax': 144, 'ymax': 92}, {'xmin': 56, 'ymin': 133, 'name': 'belt', 'xmax': 77, 'ymax': 145}, {'xmin': 106, 'ymin': 95, 'name': 'rope', 'xmax': 117, 'ymax': 138}, {'xmin': 82, 'ymin': 134, 'name': 'belt', 'xmax': 101, 'ymax': 146}], 'filename': '/Users/sw/programming/10703/project/test_images/train_image_folder/3.png'}, {'height': 210, 'width': 160, 'object': [{'xmin': 75, 'ymin': 71, 'name': 'joe', 'xmax': 86, 'ymax': 92}, {'xmin': 11, 'ymin': 98, 'name': 'key', 'xmax': 23, 'ymax': 114}, {'xmin': 85, 'ymin': 165, 'name': 'skull', 'xmax': 97, 'ymax': 180}, {'xmin': 17, 'ymin': 137, 'name': 'ladder', 'xmax': 35, 'ymax': 182}, {'xmin': 128, 'ymin': 137, 'name': 'ladder', 'xmax': 143, 'ymax': 182}, {'xmin': 70, 'ymin': 92, 'name': 'ladder', 'xmax': 90, 'ymax': 134}, {'xmin': 14, 'ymin': 51, 'name': 'door', 'xmax': 26, 'ymax': 92}, {'xmin': 133, 'ymin': 53, 'name': 'door', 'xmax': 144, 'ymax': 92}, {'xmin': 56, 'ymin': 133, 'name': 'belt', 'xmax': 77, 'ymax': 145}, {'xmin': 106, 'ymin': 95, 'name': 'rope', 'xmax': 117, 'ymax': 138}, {'xmin': 82, 'ymin': 134, 'name': 'belt', 'xmax': 101, 'ymax': 146}], 'filename': '/Users/sw/programming/10703/project/test_images/train_image_folder/4.png'}, {'height': 210, 'width': 160, 'object': [{'xmin': 75, 'ymin': 72, 'name': 'joe', 'xmax': 86, 'ymax': 93}, {'xmin': 11, 'ymin': 98, 'name': 'key', 'xmax': 23, 'ymax': 115}, {'xmin': 88, 'ymin': 165, 'name': 'skull', 'xmax': 100, 'ymax': 180}, {'xmin': 17, 'ymin': 137, 'name': 'ladder', 'xmax': 35, 'ymax': 182}, {'xmin': 128, 'ymin': 137, 'name': 'ladder', 'xmax': 143, 'ymax': 182}, {'xmin': 70, 'ymin': 93, 'name': 'ladder', 'xmax': 90, 'ymax': 135}, {'xmin': 14, 'ymin': 52, 'name': 'door', 'xmax': 27, 'ymax': 93}, {'xmin': 133, 'ymin': 53, 'name': 'door', 'xmax': 144, 'ymax': 93}, {'xmin': 56, 'ymin': 133, 'name': 'belt', 'xmax': 77, 'ymax': 145}, {'xmin': 106, 'ymin': 95, 'name': 'rope', 'xmax': 117, 'ymax': 138}, {'xmin': 83, 'ymin': 134, 'name': 'belt', 'xmax': 101, 'ymax': 146}], 'filename': '/Users/sw/programming/10703/project/test_images/train_image_folder/1.png'}, {'height': 210, 'width': 160, 'object': [{'xmin': 75, 'ymin': 71, 'name': 'joe', 'xmax': 86, 'ymax': 92}, {'xmin': 11, 'ymin': 98, 'name': 'key', 'xmax': 23, 'ymax': 114}, {'xmin': 86, 'ymin': 165, 'name': 'skull', 'xmax': 98, 'ymax': 180}, {'xmin': 17, 'ymin': 137, 'name': 'ladder', 'xmax': 35, 'ymax': 182}, {'xmin': 128, 'ymin': 137, 'name': 'ladder', 'xmax': 143, 'ymax': 182}, {'xmin': 70, 'ymin': 92, 'name': 'ladder', 'xmax': 90, 'ymax': 134}, {'xmin': 14, 'ymin': 51, 'name': 'door', 'xmax': 26, 'ymax': 92}, {'xmin': 133, 'ymin': 53, 'name': 'door', 'xmax': 144, 'ymax': 92}, {'xmin': 56, 'ymin': 133, 'name': 'belt', 'xmax': 77, 'ymax': 145}, {'xmin': 106, 'ymin': 95, 'name': 'rope', 'xmax': 117, 'ymax': 138}, {'xmin': 82, 'ymin': 134, 'name': 'belt', 'xmax': 101, 'ymax': 146}], 'filename': '/Users/sw/programming/10703/project/test_images/train_image_folder/2.png'}]\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_dir = '/Users/sw/programming/10703/project/yolo-boundingbox-labeler-GUI/bbox_txt'\n",
    "#img_dir = '/Users/sw/programming/10703/project/yolo-boundingbox-labeler-GUI/images'\n",
    "#labels = ['human', 'billiard ball', 'donut']\n",
    "#\n",
    "#train_imgs, seen_train_labels = parse_annotation(text_dir, img_dir, labels=labels)\n",
    "#### write parsed annotations to pickle for fast retrieval next time\n",
    "##with open('train_imgs', 'wb') as fp:\n",
    "##    pickle.dump(train_imgs, fp)\n",
    "#\n",
    "#### read saved pickle of parsed annotations\n",
    "##with open ('train_imgs', 'rb') as fp:\n",
    "##    train_imgs = pickle.load(fp)\n",
    "#train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
    "#\n",
    "#valid_imgs, seen_valid_labels = parse_annotation(text_dir, img_dir, labels=labels)\n",
    "#### write parsed annotations to pickle for fast retrieval next time\n",
    "##with open('valid_imgs', 'wb') as fp:\n",
    "##    pickle.dump(valid_imgs, fp)\n",
    "#\n",
    "#### read saved pickle of parsed annotations\n",
    "##with open ('valid_imgs', 'rb') as fp:\n",
    "##    valid_imgs = pickle.load(fp)\n",
    "#valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup a few callbacks and start the training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:38:15.714460Z",
     "start_time": "2017-11-26T12:38:15.708674Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights_coco.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((16, 416, 416, 3), (16, 1, 1, 1, 50, 4), (16, 13, 13, 5, 85))\n"
     ]
    }
   ],
   "source": [
    "[x_batch, b_batch], y_batch = train_batch.__getitem__(1)\n",
    "print(x_batch.shape, b_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T20:38:54.037Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 44s 44s/step - loss: 2.7174 - val_loss: 2.3193\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.31931, saving model to weights_coco.h5\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 2.3737 - val_loss: 2.1747\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.31931 to 2.17473, saving model to weights_coco.h5\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-fd2351074f53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mcallbacks\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     max_queue_size   = 3)\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2243\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tb_counter  = len([log for log in os.listdir(os.path.expanduser('/home/ubuntu/10703/basic-yolo-keras/log/')) if 'coco_' in log]) + 1\n",
    "#tensorboard = TensorBoard(log_dir=os.path.expanduser('/home/ubuntu/10703/basic-yolo-keras/log/') + 'coco_' + '_' + str(tb_counter), \n",
    "#                          histogram_freq=0, \n",
    "#                          write_graph=True, \n",
    "#                          write_images=False)\n",
    "\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "\n",
    "model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = len(train_batch), \n",
    "                    epochs           = 100, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [early_stop, checkpoint], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform detection on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T14:07:49.271978Z",
     "start_time": "2017-11-22T14:07:49.268999Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_coco.h5\")\n",
    "\n",
    "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OBJ_THRESHOLD    = 0.3 #0.5\n",
    "NMS_THRESHOLD    = 0.3 #0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T14:07:52.566171Z",
     "start_time": "2017-11-22T14:07:50.655879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAJCCAYAAABAl4f0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHUpJREFUeJzt3X3QrGV9H/Dvr4A2vlAxJEgOmIMdYgcdiwk6aWsyNqaR\nUEdM/6AwSYvFCWHGJqaTmUR0BmI6zmQmb02nTSgNVJpalEaNjGNeiCQxf0TlaA1BkIiKkZOjBEnE\nt1HRX/949qTL8Xmu52332d3n+XxmzrB737v3XtdyuL/8rvu6r63uDgCwvr+36AYAwDITlAAwICgB\nYEBQAsCAoASAAUEJAAOCEgAG5haUVXVhVd1bVfdV1avn9TkAME81jwUHquqkJH+R5F8keSDJHUku\n6+67Z/5hADBHJ8/puM9Pcl93fyxJqupNSS5Osm5QVpXlgQDYU91dW3ndvIZeDyX55NTzBybb/k5V\nXVlVR6rqyJzaAAC7Nq+KclPdfX2S6xMVJQDLa14V5dEkZ089P2uyDQBWyryC8o4k51bVOVX1uCSX\nJrl1Tp8FAHMzl6HX7n60qv59kt9LclKSG7v7Q/P4LACYp7ncHrLtRrhGCcAeW/SsVwDYFwQlAAwI\nSgAYEJQAMCAoAWBAUALAgKAEgAFBCQADghIABhb26yHAwfbQQw8N959++ul71BIYU1ECwIC1XoE9\ntV4lebx63KjKVF0yD9Z6BYAZEJQAMCAoAWBAUALAgKAEgAFBCQADghIABgQlAAwISgAYEJQAMCAo\nAWBAUALAgJ/ZAhZus5/cgkVSUQLAgKAEgAG/RwksxGbDrX6Dknnze5QAMAMqSgAOJBUlAMyAoASA\nAfdRsm/d+c5Lhvufc9EtB/KYy9JGWBUqSgAYEJQAMCAoAWBAUALAgMk87Ftf/M+POOaSHg9WiYoS\nAAYEJQAMWMKOfWGz+/y2avp+wFU45qyON49jureSZWcJOwCYAZN52BdWYULMPI65Cm2EVaeiBIAB\nQQkAAybzAHAgmcwDADMgKAFgQFACwICgBIABQQkAA4ISAAYEJQAMCEoAGBCUADAgKAFgYMdBWVVn\nV9UfVtXdVfWhqnrVZPvPVtXRqvrg5M9Fs2suAOytHa/1WlVnJjmzuz9QVU9O8v4kL0tySZLPd/cv\nbuNY1noFYE9tda3XHf8eZXcfS3Js8vhzVXVPkkM7PR4ALKOZXKOsqsNJnpvkvZNNP15Vd1bVjVV1\n2gbvubKqjlTVkVm0AQDmYdc/s1VVT0ryx0le391vraozkjyUpJP8x6wNz16xyTEMvQKwp7Y69Lqr\noKyqU5K8I8nvdfcvr7P/cJJ3dPezNzmOoARgT8399yirqpLckOSe6ZCcTPI57oeS3LXTzwCARdvN\nrNcXJPmTJH+e5OuTza9JclmS87M29Hp/kh+bTPwZHUtFCcCe2pOh11kRlADstbkPvQLAQSAoAWBA\nUALAgKAEgAFBCQADghIABgQlAAwISgAYEJQAMCAoAWBAUALAgKAEgAFBCQADghIABgQlAAwISgAY\nEJQAMCAoAWBAUALAgKAEgAFBCQADghIABgQlAAwISgAYEJQAMCAoAWBAUALAgKAEgAFBCQADghIA\nBgQlAAwISgAYEJQAMCAoAWBAUALAgKAEgAFBCQADghIABgQlAAwISgAYEJQAMCAoAWBAUALAgKAE\ngAFBCQADghIABgQlAAwISgAYEJQAMCAoAWDg5EU3IEme/O3fludde9WimwHAAXHH667b8mtVlAAw\nICgBYEBQAsCAoASAgV1N5qmq+5N8LsnXkjza3RdU1VOTvDnJ4ST3J7mku/9md80EgMWYRUX5z7v7\n/O6+YPL81Une1d3nJnnX5DkArKR5DL1enOSmyeObkrxsDp8BAHuiunvnb676eJLPZm3o9b919/VV\n9bfd/ZTJ/kryN8efD46z80YAwA50d23ldbtdcOAF3X20qr41yW1V9eETGtEbhWBVXZnkyl1+PgDM\n1a4qysccqOpnk3w+yY8meWF3H6uqM5P8UXc/c5P3qigB2FNbrSh3fI2yqp5YVU8+/jjJDyS5K8mt\nSS6fvOzyJG/f6WcAwKLtuKKsqmckedvk6clJ/nd3v76qvjnJLUmenuQTWbs95OFNjqWiBGBPbbWi\nnNnQ624ISgD22tyHXgHgIBCUADAgKAFgQFACwMBuFxxgHZ868ootve5pF9ww55YAbM45a0xFCQAD\nbg8B4EByewgAzICgBIABk3nmwIVxYJU4Z42pKAFgQFACwIBZrwAcSGa9AsAMmMwzBy6MA6vEOWtM\nRQkAA4ISAAZM5gHgQDKZBwBmwGSeOXBhHFglzlljKkoAGBCUADBgMg8AB5LJPAAwA4ISAAbMep0D\nM8iAVeKcNaaiBIABk3kAOJBM5gGAGRCUADBgMs8cuDAOrBLnrDEVJQAMmMwDwIFkMg8AzICgBIAB\nk3nmwIVxYJU4Z42pKAFgQFACwIBZrwAcSGa9AsAMmMwzBy6MA6vEOWtMRQkAA4ISAAZM5gHgQDKZ\nBwBmwGSeOXBhHFglzlljKkoAGBCUADBgMg8AB5LJPAAwA4ISAAbMep0DM8iAVeKcNaaiBIABk3lg\nBd35zkuG+59z0S171BJYXSbzAMAMCEoAGNjxZJ6qemaSN09tekaSa5I8JcmPJvnryfbXdPc7d9zC\nFeTCOLBKnLPGdhyU3X1vkvOTpKpOSnI0yduS/Lskv9LdvziTFgLAAs3q9pAXJflod3+iakvXRve1\ng/p/XeydL/7nRxbdBPYR56yxWV2jvDTJzVPPf7yq7qyqG6vqtBl9BgDsuV0HZVU9LslLk/yfyaZf\nz9r1yvOTHEvySxu878qqOlJVR3bbBgCYl13fR1lVFyd5ZXf/wDr7Did5R3c/e5Nj7Kv7KF0YZ7c2\nu09yJ9xbyUYO6jlrL++jvCxTw65VdebUvh9KctcMPgMAFmJXFWVVPTHJXyZ5Rnd/drLtN7M27NpJ\n7k/yY919bJPj7KuKEnbrPRdeOPNjfvfv/u7MjwmrbKsV5a5mvXb3F5J88wnb/s1ujgkAy8TKPAAw\nYFH0OTioF8aZrwde9aq/e3zWr/7qN2ybdnw/bMVBPWdZFB0AZkBQAsCAoVdYERsNs67H0CtsztAr\nAMzArBZFZ8pBvTDOfE1XidupLmEzzlljKkoAGBCUADBgMg+siJ0sa2fZOtiYyTwAMAMm88yBC+PM\n2/FKcbMqc3q/6pKNOGeNqSgBYEBQAsCAyTyw5Gb125SGXuGxTOYBgBkQlAAwYNbrHJhBxrxtddYr\nbIVz1piKEgAGTOaBFbGd6tHEHdicyTwAMAOCEgAGTOaZAxfGmbfNJvOst91wLBtxzhpTUQLAgMk8\nsCJ2eyuIihIey2QeAJgBQQkAAybzzIEL4+yVjYZTrdjDdjhnjakoAWBAUALAgKHXOTiowxPM1xN+\n4tRv3LjBRNbtvBacs8ZUlAAwoKKcAxfGgVXinDWmogSAAUEJAAOGXufgoA5PMB93vvOSmb4OTuSc\nNaaiBIABFSXsY8+56JZFNwFWnooSAAYEJQAMLMXvUZ56+FA/79qrFt0MVtjtV1yzsM/+vht/bmGf\nvWi+d1bVHa+7Lo/cf9TvUQLAbglKABgQlAAwICgBYEBQAsCAoASAAUEJAAP7dgm7Rd7fxcGynb9r\nW733bx5/fxf52fMw63ZO/yajRcKXzyLvm1VRAsCAoASAAUEJAAOCEgAGBCUADAhKABjYt7eHzMr0\nlPH1mEYOsL9tWlFW1Y1V9WBV3TW17alVdVtVfWTyz9Om9l1dVfdV1b1V9eJ5NRwA9sJWhl7fkOTC\nE7a9Osm7uvvcJO+aPE9VnZfk0iTPmrzn16rqpJm1FgD22KZDr9397qo6fMLmi5O8cPL4piR/lORn\nJtvf1N1fTvLxqrovyfOT/Olsmrs3NhtuXe+1hmAB9qedTuY5o7uPTR5/KskZk8eHknxy6nUPTLZ9\ng6q6sqqOVNWRr3z+CztsBgDM165nvXZ3J+kdvO/67r6guy943JOeuNtmAMBc7HTW66er6szuPlZV\nZyZ5cLL9aJKzp1531mTbSlhvyPX4kOpGCyYf325BZWZpkQtAA4+104ry1iSXTx5fnuTtU9svrarH\nV9U5Sc5N8r7dNREAFmfTirKqbs7axJ3Tq+qBJNcm+fkkt1TVK5J8IsklSdLdH6qqW5LcneTRJK/s\n7q/Nqe1zs15FuFGVuF7FCcD+sZVZr5dtsOtFG7z+9Ulev5tGAcCysIQdAAxYwm4d603M2WwyD8zS\n7VdcM/NjmiAEO6OiBIABFeWU9arH9SrG0W0kAOwvKkoAGBCUADBg6HUd25msY8gVYH9TUQLAgKAE\ngAFBCQADghIABkzm2cRmK/MAsL+pKAFgQFACwIChV1hCFjCH5aGiBIABQQkAA4ISAAYEJQAMmMyz\nic0WRYd5uP2Ka2Z+TBOEYGdUlAAwICgBYEBQbuJpF9xgyTqAA0xQAsCAyTybMJkH4GBTUQLAgKAE\ngAFBuQmTeQAONkEJAAMm82yRqhLgYFJRAsCAoASAAUOvsIQsYA7LQ0UJAAOCEgAGBCUADAhKABgw\nmQeW0O1XXDPzY5ogBDujogSAAUEJAAOCEgAGBCUADAhKABgQlAAwICgBYEBQAsCAoASAAUEJAAOC\nEgAGBCUADFgUHZaQBcxheagoAWBAUALAgKAEgAFBCQADJvPAErr9imtmfkwThGBnNq0oq+rGqnqw\nqu6a2vYLVfXhqrqzqt5WVU+ZbD9cVV+qqg9O/lw3z8YDwLxtZej1DUkuPGHbbUme3d3PSfIXSa6e\n2vfR7j5/8ueq2TQTABZj06Ds7ncnefiEbb/f3Y9Onr4nyVlzaBsALNwsJvNckeR3pp6fMxl2/eOq\n+p6N3lRVV1bVkao68pXPf2EGzQCA2dvVZJ6qem2SR5O8cbLpWJKnd/dnquq7kvx2VT2rux858b3d\nfX2S65Pk1MOHejftAIB52XFFWVUvT/KSJD/c3Z0k3f3l7v7M5PH7k3w0yXfMoJ0AsBA7CsqqujDJ\nTyd5aXd/cWr7t1TVSZPHz0hybpKPzaKhALAImw69VtXNSV6Y5PSqeiDJtVmb5fr4JLdVVZK8ZzLD\n9XuT/FxVfTXJ15Nc1d0Pr3tgAFgBmwZld1+2zuYbNnjtW5K8ZbeNAoBlYQk7ABgQlAAwICgBYMCi\n6LCELGAOy0NFCQADghIABgQlAAwISgAYMJkHltDtV1wz82OaIAQ7o6IEgAFBCQADghIABgQlAAwI\nSgAYEJQAMCAoAWBAUALAgKAEgAFBCQADlrCDPTSPpelW4bNXwdMuuGHRTWBJqSgBYGDfVpQWgB5T\nXWxuq3+HtvNdzuOYi/zsRfZnv3HOWl4qSgAYEJQAMLBvh15ht+YxXLjVY85jGG6R/YFVpqIEgAEV\nJQfOQZ00sQr9VqGyjFSUADAgKAFgwNDrHKzKPXAH1Sp8R6symYfZmfVEr0Weh/YbFSUADAhKABgw\n9MqBM+uhq+0MR231mIscJp1Hf1w6YJWpKAFgQEXJgTPrqmW/VUFW8IHHUlECwICgBIABQQkAA4IS\nAAYEJQAMCEoAGBCUADDgPso5OKgLBwPLw3lodlSUADAgKAFgQFACwICgBIABk3nmwC+LA4vmPDQ7\nKkoAGBCUADAgKAFgQFACwICgBIABQQkAA4ISAAY2DcqqurGqHqyqu6a2/WxVHa2qD07+XDS17+qq\nuq+q7q2qF8+r4QCwF7ZSUb4hyYXrbP+V7j5/8uedSVJV5yW5NMmzJu/5tao6aVaNBYC9tmlQdve7\nkzy8xeNdnORN3f3l7v54kvuSPH8X7QOAhdrNEnY/XlX/NsmRJD/V3X+T5FCS90y95oHJtqHPfeKv\nZr7c0kFdagmA2drpZJ5fT/KMJOcnOZbkl7Z7gKq6sqqOVNWRHbYBAOZuRxVld3/6+OOq+u9J3jF5\nejTJ2VMvPWuybb1jXJ/k+iQ59fChft61V+2kKUtJNQssmvPQ7OyooqyqM6ee/lCS4zNib01yaVU9\nvqrOSXJukvftrokAsDibVpRVdXOSFyY5vaoeSHJtkhdW1flJOsn9SX4sSbr7Q1V1S5K7kzya5JXd\n/bX5NB0A5m/ToOzuy9bZfMPg9a9P8vrdNAoAloWVeQBgYDe3h7ABvywOLJrz0OyoKAFgQFACwICg\nBIABQQkAA4ISAAYEJQAMCEoAGBCUADAgKAFgQFACwICgBIABQQkAAxZFn4ODunAwsDych2ZHRQkA\nA4ISAAYEJQAMCEoAGDCZZw78sjiwaM5Ds6OiBIABQQkAA4ISAAYEJQAMCEoAGBCUADAgKAFgQFAC\nwICgBIABQQkAA4ISAAYEJQAMWBR9Dg7qwsHA8nAemh0VJQAMCEoAGDD0CmzqoYceGu4//fTT96gl\nsPdUlAAwICgBYMDQ6xzcfsU1Mz+mGWwswmZDruu9zjDscnAemh0VJQAMqCiBDR2vDjeqGI9vV0Wy\nn6koAWBAUALAgKFXYEPrDa2uNwxrMg/7mYoSAAZUlMCmNrpNZKu3j8AqU1ECwICgBIABQ6/AY+x2\nONW9lew3KkoAGBCUADBg6HUODurCwcDycB6aHRUlAAyoKIENrTchZ7NVeNxbyX6jogSAAUEJAAOb\nDr1W1Y1JXpLkwe5+9mTbm5M8c/KSpyT52+4+v6oOJ7knyb2Tfe/p7qtm3ehl55fF2S+2ek+k4dbl\n4zw0O1u5RvmGJP8lyf88vqG7//Xxx1X1S0k+O/X6j3b3+bNqIAAs0qZB2d3vnlSK36CqKsklSb5v\nts0ClolF0TnIdnuN8nuSfLq7PzK17Zyq+mBV/XFVfc9Gb6yqK6vqSFUd+crnv7DLZgDAfOz29pDL\nktw89fxYkqd392eq6ruS/HZVPau7Hznxjd19fZLrk+TUw4d6l+0AgLnYcUVZVScn+VdJ3nx8W3d/\nubs/M3n8/iQfTfIdu20kACzKboZevz/Jh7v7geMbqupbquqkyeNnJDk3ycd210QAWJxNg7Kqbk7y\np0meWVUPVNUrJrsuzWOHXZPke5PcWVUfTPJbSa7q7odn2WAA2EtbmfV62QbbX77OtrckecvumwUs\nyvQ9kzuZ1ep3KNlvrMwDAAMWRQc2dLw63KyyVEWyn6koAWBAUALAgKFXYFOGVjnIVJQAMFDdi189\n7tTDh/p51x64X+MCYEHueN11eeT+o7WV16ooAWBAUALAwFJM5vnSQ6fk7hsObfq6815xdMvH3Mrx\ntnPMrR5vVY7pu5zdMX2Xszum73J2x/Rdzo6KEgAGBCUADAhKABgQlAAwICgBYEBQAsCAoASAgaW4\nj/KbTv/qlu57Oaj3JM3jmL7L2R3Tdzm7Y/ouZ3dM3+XYlx46ZcvHU1ECwICgBIABQQkAA4ISAAYE\nJQAMCEoAGKjuXnQbcurhQ/28a69adDMAOCDueN11eeT+o7WV16ooAWBAUALAwFKszPOlh07Z0koK\nB3WVi3kc03c5u2P6Lmd3TN/l7I7pu5wdFSUADAhKABgQlAAwICgBYEBQAsCAoASAAUEJAANLcR/l\nN53+1S3d93JQ70maxzF9l7M7pu9ydsf0Xc7umL7LsS89dMqWj6eiBIABQQkAA4ISAAYEJQAMCEoA\nGBCUADAgKAFgoLp70W3IqYcP9fOuvWrRzQDggLjjddflkfuP1lZeq6IEgIGlWJnnSw+dsqWVFA7q\nKhfzOKbvcnbH9F3O7pi+y9kd03c5OypKABgQlAAwICgBYEBQAsCAoASAAUEJAAOCEgAGlmJlnqpa\nfCMAOFC628o8ALBbghIABjYNyqo6u6r+sKrurqoPVdWrJtufWlW3VdVHJv88beo9V1fVfVV1b1W9\neJ4dAIB52vQaZVWdmeTM7v5AVT05yfuTvCzJy5M83N0/X1WvTnJad/9MVZ2X5OYkz0/ybUn+IMl3\ndPfXBp/hGiUAe2pm1yi7+1h3f2Dy+HNJ7klyKMnFSW6avOymrIVnJtvf1N1f7u6PJ7kva6EJACtn\nW9coq+pwkucmeW+SM7r72GTXp5KcMXl8KMknp972wGTbice6sqqOVNWRbbYZAPbMloOyqp6U5C1J\nfrK7H5ne12vjt9saPu3u67v7gu6+YDvvA4C9tKWgrKpTshaSb+zut042f3py/fL4dcwHJ9uPJjl7\n6u1nTbYBwMrZyqzXSnJDknu6+5endt2a5PLJ48uTvH1q+6VV9fiqOifJuUneN7smA8De2cqs1xck\n+ZMkf57k65PNr8nadcpbkjw9ySeSXNLdD0/e89okVyR5NGtDtb+zyWeY9QrAntrqrFdL2AFwIFnC\nDgBmQFACwICgBIABQQkAA4ISAAYEJQAMCEoAGBCUADAgKAFgQFACwICgBIABQQkAA4ISAAYEJQAM\nCEoAGBCUADAgKAFgQFACwICgBICBkxfdgImHknwiyemTx/vBfupLoj/Lbj/1Zz/1JdGfZfXtW31h\ndfc8G7ItVXWkuy9YdDtmYT/1JdGfZbef+rOf+pLoz35g6BUABgQlAAwsW1Bev+gGzNB+6kuiP8tu\nP/VnP/Ul0Z+Vt1TXKAFg2SxbRQkAS2UpgrKqLqyqe6vqvqp69aLbs11VdXZV/WFV3V1VH6qqV022\nP7Wqbquqj0z+edqi27pVVXVSVf3fqnrH5Pkq9+UpVfVbVfXhqrqnqv7JivfnP0z+nt1VVTdX1d9f\npf5U1Y1V9WBV3TW1bcP2V9XVk3PDvVX14sW0emMb9OcXJn/f7qyqt1XVU6b2rVx/pvb9VFV1VZ0+\ntW2p+zMLCw/KqjopyX9N8oNJzktyWVWdt9hWbdujSX6qu89L8t1JXjnpw6uTvKu7z03yrsnzVfGq\nJPdMPV/lvvxqkt/t7n+U5B9nrV8r2Z+qOpTkJ5Jc0N3PTnJSkkuzWv15Q5ILT9i2bvsn/x1dmuRZ\nk/f82uScsUzekG/sz21Jnt3dz0nyF0muTla6P6mqs5P8QJK/nNq2Cv3ZtYUHZZLnJ7mvuz/W3V9J\n8qYkFy+4TdvS3ce6+wOTx5/L2on4UNb6cdPkZTcledliWrg9VXVWkn+Z5DemNq9qX/5Bku9NckOS\ndPdXuvtvs6L9mTg5yTdV1clJnpDkr7JC/enudyd5+ITNG7X/4iRv6u4vd/fHk9yXtXPG0livP939\n+9396OTpe5KcNXm8kv2Z+JUkP51kemLL0vdnFpYhKA8l+eTU8wcm21ZSVR1O8twk701yRncfm+z6\nVJIzFtSs7fpPWfsP4utT21a1L+ck+esk/2MylPwbVfXErGh/uvtokl/M2v/VH0vy2e7+/axof6Zs\n1P79cH64IsnvTB6vZH+q6uIkR7v7z07YtZL92a5lCMp9o6qelOQtSX6yux+Z3tdr04uXfopxVb0k\nyYPd/f6NXrMqfZk4Ocl3Jvn17n5uki/khGHJVerP5NrdxVn7H4BvS/LEqvqR6desUn/Ws+rtn1ZV\nr83apZk3LrotO1VVT0jymiTXLLoti7IMQXk0ydlTz8+abFspVXVK1kLyjd391snmT1fVmZP9ZyZ5\ncFHt24Z/luSlVXV/1obBv6+q/ldWsy/J2v/hPtDd7508/62sBeeq9uf7k3y8u/+6u7+a5K1J/mlW\ntz/HbdT+lT0/VNXLk7wkyQ/3/78PbxX78w+z9j9mfzY5L5yV5ANV9bSsZn+2bRmC8o4k51bVOVX1\nuKxdGL51wW3alqqqrF0Du6e7f3lq161JLp88vjzJ2/e6bdvV3Vd391ndfThr/y5u7+4fyQr2JUm6\n+1NJPllVz5xselGSu7Oi/cnakOt3V9UTJn/vXpS1a+Kr2p/jNmr/rUkurarHV9U5Sc5N8r4FtG9b\nqurCrF2+eGl3f3Fq18r1p7v/vLu/tbsPT84LDyT5zsl/WyvXnx3p7oX/SXJR1maGfTTJaxfdnh20\n/wVZGyq6M8kHJ38uSvLNWZvB95Ekf5DkqYtu6zb79cIk75g8Xtm+JDk/yZHJv5/fTnLaivfndUk+\nnOSuJL+Z5PGr1J8kN2ft+upXs3bSfcWo/UleOzk33JvkBxfd/i32576sXbs7fj64bpX7c8L++5Oc\nvir9mcUfK/MAwMAyDL0CwNISlAAwICgBYEBQAsCAoASAAUEJAAOCEgAGBCUADPw/V5TtMlklKc8A\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f6d0610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#image = cv2.imread('images/giraffe.jpg')\n",
    "image = cv2.imread('../../test_images/train_image_folder/1.png')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "input_image = cv2.resize(image, (416, 416))\n",
    "input_image = input_image / 255.\n",
    "input_image = input_image[:,:,::-1]\n",
    "input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "netout = model.predict([input_image, dummy_array])\n",
    "#print(netout)\n",
    "\n",
    "boxes = decode_netout(netout[0], \n",
    "                      obj_threshold=OBJ_THRESHOLD,\n",
    "                      nms_threshold=NMS_THRESHOLD,\n",
    "                      anchors=ANCHORS, \n",
    "                      nb_class=len(labels))\n",
    "image = draw_boxes(image, boxes, labels=labels)\n",
    "\n",
    "plt.imshow(image[:,:,::-1]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform detection on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-06T13:28:28.029334Z",
     "start_time": "2017-10-06T13:28:28.024662Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_coco.h5\")\n",
    "\n",
    "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-06T13:39:09.640646Z",
     "start_time": "2017-10-06T13:31:44.627609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4666/4666 [07:24<00:00, 10.49it/s]\n"
     ]
    }
   ],
   "source": [
    "video_inp = '../basic-yolo-keras/images/phnom_penh.mp4'\n",
    "video_out = '../basic-yolo-keras/images/phnom_penh_bbox.mp4'\n",
    "\n",
    "video_reader = cv2.VideoCapture(video_inp)\n",
    "\n",
    "nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "video_writer = cv2.VideoWriter(video_out,\n",
    "                               cv2.VideoWriter_fourcc(*'XVID'), \n",
    "                               50.0, \n",
    "                               (frame_w, frame_h))\n",
    "\n",
    "for i in tqdm(range(nb_frames)):\n",
    "    ret, image = video_reader.read()\n",
    "    \n",
    "    input_image = cv2.resize(image, (416, 416))\n",
    "    input_image = input_image / 255.\n",
    "    input_image = input_image[:,:,::-1]\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    netout = model.predict([input_image, dummy_array])\n",
    "\n",
    "    boxes = decode_netout(netout[0], \n",
    "                          obj_threshold=0.3,\n",
    "                          nms_threshold=NMS_THRESHOLD,\n",
    "                          anchors=ANCHORS, \n",
    "                          nb_class=CLASS)\n",
    "    image = draw_boxes(image, boxes, labels=LABELS)\n",
    "\n",
    "    video_writer.write(np.uint8(image))\n",
    "    \n",
    "video_reader.release()\n",
    "video_writer.release()  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {
    "height": "381px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "758px",
    "left": "0px",
    "right": "1096px",
    "top": "73px",
    "width": "253px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
